!pip install groq
!pip install gensim
-----------------------------------------
!pip install groq
---------------------------------------
from gensim.models import KeyedVectors
import groq
------------------------------------
def load_word_vectors():
    model_path ="/kaggle/input/google-word2vec/GoogleNews-vectors-negative300.bin"
    model = KeyedVectors.load_word2vec_format(model_path, binary = True)
    return model
model = load_word_vectors()
---------------------------------
def get_similar_words(word, model, top_n=3):
    try:
        similar_words = model.most_similar(word, topn=top_n)
        return [w[0] for w in similar_words]
    except KeyError:
        return []

word = "good"
word_vector = get_similar_words (word, model)
word_vector
--------------------------------------
from kaggle_secrets import UserSecretsClient
def generate_response(prompt, model_name="deepseek-r1-distill-llama-70b"): #using LLAMA model
    user_secrets = UserSecretsClient()
    groq_api_key = user_secrets.get_secret("GROQ_API_KEY")
    if not groq_api_key:
        raise ValueError("GROQ_API_KEY environment variable is not set.")
    client = groq.Client(api_key=groq_api_key)
    response = client.chat.completions.create(
        model=model_name,
        messages=[{"role":"system","content": "you are a helpful AI assistant."},
                 {"role":"user","content": prompt}]
    )

    return response.choices[0].message.content
original_prompt = "Describe the future of artificial intelligence in gaming."
response = generate_response(original_prompt)
print(response)
------------------------------------
def enrich_prompt(prompt, model, max_enrichments=2):
    words = prompt.split()
    enriched_words = []

    for word in words:
        similar_words = get_similar_words(word, model, top_n=max_enrichments)
        filtered_similar_words = [w for w in similar_words if w.isalpha()] #ensure only valid words

        if filtered_similar_words:
            enriched_words.append(word + " (" + ", ".join(filtered_similar_words) + ")")
        else:
            enriched_words.append(word)

    return " ".join(enriched_words)
enriched_prompt = enrich_prompt(original_prompt, model)

print("Original Prompt:", original_prompt)
print("Enriched Prompt:", enriched_prompt)
--------------------------------------------------------
original_response = generate_response(original_prompt)
enriched_response = generate_response(enriched_prompt)

print("\nOriginal Response:\n", original_response)
print("\Enriched Response:\n", enriched_response)
---------------------------------------------------
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
def analyze_responses(original_response, enriched_response):
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform([original_response, enriched_response])
    similarity_score = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]

    original_length = len(original_response.split())
    enriched_length = len(enriched_response.split())

    print("\nresponse Analysis:")
    print("Similarity Score:", round(similarity_score, 4))
    print("Original Response Word Count:", original_length)
    print("enriched Response Word Count:", enriched_length)

analyze_responses(original_response, enriched_response)
-------------------------------------------------------
